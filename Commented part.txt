   # Copying image to show on output
    out_image = image.copy()

    # saving the image to get the proper dimensions
    cv2.imwrite('out_image.jpg', out_image)
    # reading the image from the root directory again to get proper alignments
    frame = cv2.imread('out_image.jpg')
    # resizing the image to have 192*192*3 (MoveNet specified Tensor)
    resized = cv2.resize(frame, (192, 192), interpolation=cv2.INTER_LINEAR)

    # Expanding the dimensions
    img = tf.image.resize_with_pad(np.expand_dims(resized, axis=0), 192, 192)
    input_image = tf.cast(img, dtype=tf.float32)

    # Setup input and output
    input_details = MoveNetmodel.get_input_details()
    output_details = MoveNetmodel.get_output_details()

    # Make predictions
    MoveNetmodel.set_tensor(input_details[0]['index'], np.array(input_image))
    MoveNetmodel.invoke()
    keypoints_with_scores = MoveNetmodel.get_tensor(output_details[0]['index'])

    # Flattening the Keypoints
    flat = keypoints_with_scores.flatten()

    # Reshaping to 51 columns
    reshaped = flat.reshape(-1, 1)

    # Predicting the results
    res = model2.predict(np.expand_dims(reshaped, axis=0))[0]

    # Rendering
    draw_connections(resized, keypoints_with_scores, EDGES, detection_confidence)
    draw_keypoints(resized, keypoints_with_scores, detection_confidence)

    # Checking if the detected Keypoints are same as the classes then print Class name
    if res[np.argmax(res)] > threshold:
        # Make a h1 tag header
        kpi1_text.write(f"<h1 style='text-align: center; color:red;'> {actions[np.argmax(res)]} </h1>",
                        unsafe_allow_html=True)
    else:
        # Make a h1 tag header
        kpi1_text.write(f"<h1 style='text-align: center; color:red;'> {Unknown_Pose} </h1>", unsafe_allow_html=True)

    # Display the Image
    st.subheader('Output Image')
    st.image(resized, use_column_width=True)
